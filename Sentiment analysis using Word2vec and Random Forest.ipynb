{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"labeledTrainData.tsv\", header=0,\\\n",
    "                    delimiter=\"\\t\", quoting=3)\n",
    "\n",
    "test = pd.read_csv(\"testData.tsv\",header=0,\\\n",
    "                    delimiter=\"\\t\", quoting=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_word_list(review):\n",
    "    review_text=BeautifulSoup(review,'lxml').get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \",review_text)\n",
    "    words= review_text.lower().split()\n",
    "    words= [w for w in words if not w in set(stopwords.words('english'))]\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk.data\n",
    "tokenizer= nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def review_sentence(review, tokenizer):\n",
    "    raw_sentences = tokenizer.tokenize(review.strip().decode('utf-8'))\n",
    "    sentences=[]\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence)>0:\n",
    "            a=review_word_list(raw_sentence)\n",
    "            sentences.append(a)\n",
    "    \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentences=[]\n",
    "i=0\n",
    "for review in train['review']:\n",
    "    if i%100==0:\n",
    "        print i , \"out of \", len(train['review'])\n",
    "    \n",
    "    sentences+=review_sentence(review,tokenizer)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model....\n"
     ]
    }
   ],
   "source": [
    "num_features = 300  # Word vector dimensionality\n",
    "min_word_count = 40 # Minimum word count\n",
    "num_workers = 4     # Number of parallel threads\n",
    "context = 10        # Context window size\n",
    "downsampling = 1e-3 # (0.001) Downsample setting for frequent words\n",
    "\n",
    "from gensim.models import word2vec\n",
    "print(\"Training model....\")\n",
    "model = word2vec.Word2Vec(sentences,\\\n",
    "                          workers=num_workers,\\\n",
    "                          size=num_features,\\\n",
    "                          min_count=min_word_count,\\\n",
    "                          window=context,\n",
    "                          sample=downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'planet'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"man woman dog child planet\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'berlin'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"france england germany berlin\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'girl', 0.701718807220459),\n",
       " (u'lady', 0.6968203186988831),\n",
       " (u'naive', 0.6901925802230835),\n",
       " (u'man', 0.6895425319671631),\n",
       " (u'husband', 0.6844757795333862),\n",
       " (u'lover', 0.6837038397789001),\n",
       " (u'innocent', 0.6774181723594666),\n",
       " (u'sexually', 0.6763538122177124),\n",
       " (u'daughter', 0.6626691818237305),\n",
       " (u'widow', 0.6623377799987793)]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"woman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'terrible', 0.883781909942627),\n",
       " (u'horrible', 0.871444582939148),\n",
       " (u'dreadful', 0.8066338300704956),\n",
       " (u'sucks', 0.7981616258621216),\n",
       " (u'atrocious', 0.776829183101654),\n",
       " (u'horrendous', 0.7615725994110107),\n",
       " (u'abysmal', 0.7599791288375854),\n",
       " (u'crappy', 0.7576720714569092),\n",
       " (u'horrid', 0.7543565034866333),\n",
       " (u'pathetic', 0.7488211393356323)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"awful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model['awful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(words,num_features,model):\n",
    "    feature= np.zeros(num_features,dtype='float32')\n",
    "    nwords=0\n",
    "    \n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            nwords=nwords+1\n",
    "            \n",
    "            feature=np.add(feature,model[word])\n",
    "    \n",
    "    feature=np.divide(feature,nwords)\n",
    "    return feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def avg_features(reviews,num_features,model):\n",
    "    counter=0\n",
    "    avg_feature_vec=np.zeros((len(reviews),num_features),dtype='float32')\n",
    "    for review in reviews:\n",
    "        avg_feature_vec[counter]=features(review,num_features,model)\n",
    "        counter=counter+1\n",
    "    \n",
    "    return avg_feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_reviews = []\n",
    "i=0\n",
    "for review in train['review']:\n",
    "    if i%100==0:\n",
    "        print i , \"out of \", len(train['review'])\n",
    "        \n",
    "    clean_train_reviews.append(review_word_list(review))\n",
    "    i=i+1\n",
    "\n",
    "train_data_vector = avg_features(clean_train_reviews,num_features,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clean_test_reviews = []\n",
    "i=0\n",
    "for review in test['review']:\n",
    "    if i%100==0:\n",
    "        print i , \"out of \", len(test['review'])\n",
    "        \n",
    "    clean_test_reviews.append(review_word_list(review))\n",
    "    i=i+1\n",
    "test_data_vector = avg_features(clean_test_reviews,num_features,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting random forest to training data....\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.85243999999999998"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LogisticRegression\n",
    "lg = LogisticRegression()\n",
    "    \n",
    "print(\"Fitting random forest to training data....\")    \n",
    "forest.fit(train_data_vector, train[\"sentiment\"])\n",
    "pred=forest.predict(train_data_vector)\n",
    "forest.score(train_data_vector,train[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10537  1963]\n",
      " [ 1726 10774]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(train[\"sentiment\"],pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.84      0.85     12500\n",
      "          1       0.85      0.86      0.85     12500\n",
      "\n",
      "avg / total       0.85      0.85      0.85     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train[\"sentiment\"],pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
